{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the following libraries\n",
    "\n",
    "1. **PyTube:** To faciliate YouTube video downloads and manipulation.\n",
    "\n",
    "```jupyter\n",
    "! pip install pytube\n",
    "```\n",
    "<br>\n",
    "\n",
    "2. **PyDub:** To import and manipulate audio files.\n",
    "\n",
    "```jupyter\n",
    "! pip install pydub\n",
    "```\n",
    "<br>\n",
    "\n",
    "**Dcoumentation:**\n",
    "- PyTube Documentation --> [click here](https://pytube.io/en/latest/index.html)\n",
    "- PyDub Documentation --> [click here](https://github.com/jiaaro/pydub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the executable files for FFmpeg\n",
    "*The purpose of FFmpeg is to \"record, convert and stream audio and video\"*\n",
    "\n",
    "1. Follow this link [here](https://ffmpeg.org/download.html) to download the packages and executables.\n",
    "<br>\n",
    "\n",
    "2. Download the appropriate zipped folder for your operating system.\n",
    "<br>\n",
    "\n",
    "3. Unzip/Extract the files.\n",
    "<br>\n",
    "\n",
    "4. It's important to note that for some reason not discussed in the pydub documentation, the following executable files should be placed in the script/notebook directory:\n",
    "    - ffmpeg.exe\n",
    "    - ffprobe.exe\n",
    "    - ffplay.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pytube import YouTube\n",
    "\n",
    "#class from the pydub package is imported to manipulate audio files, such as slicing and exporting.\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# after much debugging, this seems important:\n",
    "AudioSegment.converter = r'C:\\Users\\Administrator\\Desktop\\repos\\auto_caption\\ffmpeg.exe'                        \n",
    "# AudioSegment.ffprobe   = r'C:\\Users\\Administrator\\Desktop\\repos\\auto_caption\\ffprobe.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gf7_1_5ink31",
    "outputId": "b3a029c0-b8f1-47f9-ee37-67ae8dddb8e8"
   },
   "outputs": [],
   "source": [
    "# URL of a trial-video\n",
    "URL = 'https://www.youtube.com/watch?v=xR7qcezLcXI'\n",
    "\n",
    "# create a YouTube object from pytube library\n",
    "yt = YouTube(URL)\n",
    "\n",
    "#The audio stream of the YouTube video is filtered and the first available audio stream is selected.\n",
    "# this could all be condenced into one line of code:\n",
    "# first_audio_stream = youtube.streams.filter(only_audio=True).first()\n",
    "video_stream_query = yt.streams\n",
    "audio = video_stream_query.filter(only_audio=True)\n",
    "first_audio_stream = audio.first()  # returns Stream object (or None)\n",
    "\n",
    "trial_audio_filepath = first_audio_stream.download(filename='trial_audio.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='first_minute_audio.wav'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load audio from mp4 file...  \n",
    "audio = AudioSegment.from_file(trial_audio_filepath, format=\"mp4\")\n",
    "\n",
    "# slice audio\n",
    "one_minute = 1 * 60 * 1_000  # number of min desired for this trial (in ms)\n",
    "first_minute = audio[:one_minute]\n",
    "\n",
    "first_minute_filename = 'first_minute_audio.wav'\n",
    "\n",
    "# Export the audio\n",
    "first_minute.export(first_minute_filename, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "200cy_Brscd1",
    "outputId": "a33d0f3c-f7d3-46f9-9373-d059698b4cd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-y', '-i', 'first_minute_audio.wav', '-ar', '16000', 'eng_10_16k.wav'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "input_filename = first_minute_filename\n",
    "output_filename = \"eng_10_16k.wav\"\n",
    "\n",
    "#The command list is created, which represents the command to be executed using FFmpeg. \n",
    "# It specifies the input file, the desired audio sample rate of 16000 Hz, and the output file.\n",
    "\n",
    "command = ['ffmpeg', '-y', '-i', input_filename, '-ar', '16000', output_filename]\n",
    "\n",
    "#The subprocess.run() function is called to execute the FFmpeg command. \n",
    "#This command will resample the input audio file to a sample rate of 16000 Hz and save it as the output file.\n",
    "\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAIW6wf-oKbt",
    "outputId": "0d4d4df4-59ab-44eb-c5fe-db04d0ee811e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'fairseq'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: '/content/fairseq'\n",
      "C:\\Users\\Administrator\\Desktop\\repos\\auto_caption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Administrator/Desktop/repos/auto_caption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file:///C:/Users/Administrator/Desktop/repos/auto_caption does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboardX) (1.24.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboardX) (23.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboardX) (3.20.3)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 41.0/101.7 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.7/101.7 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6.2.2\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"temp_dir\"\n",
    "\n",
    "#git clone command. \n",
    "#It fetches the source code and creates a local copy of the repository on your machine.\n",
    "\n",
    "!git clone https://github.com/pytorch/fairseq\n",
    "\n",
    "# Change current working directory\n",
    "#The !pwd command prints the current working directory, displaying the current path. \n",
    "!pwd\n",
    "\n",
    "#The %cd command changes the current working directory to \"/content/fairseq\".\n",
    "\n",
    "%cd \"/content/fairseq\"\n",
    "\n",
    "#The --editable flag indicates that the package should be installed in editable mode, \n",
    "#allowing modifications to the package source code without needing to reinstall it.\n",
    "#./ refers to the current directory\n",
    "!pip install --editable ./ \n",
    "\n",
    "#tensorboardX is a library that provides a wrapper around TensorFlow's \n",
    "#TensorBoard, enabling visualization and logging of training progress and results.\n",
    "\n",
    "!pip install tensorboardX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0jrZ-gIsVTV"
   },
   "outputs": [],
   "source": [
    "# use colab free\n",
    "# MMS-1B:FL102 model - 102 Languages - FLEURS Dataset\n",
    "#!wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_fl102.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoecrJRInviT",
    "outputId": "cb9d45ef-233e-4fb2-93d7-1d1bd362c91a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# use high RAM, such as colab pro\n",
    "# # MMS-1B-all - 1162 Languages - MMS-lab + FLEURS + CV + VP + MLS\n",
    "! wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_all.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdyCmaVNtuFa"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "# Set the value of the environment variable \"TMPDIR\"\n",
    "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
    "\n",
    "# Set the value of the environment variable \"PYTHONPATH\"\n",
    "os.environ[\"PYTHONPATH\"] = \".\"\n",
    "\n",
    "# Set the value of the environment variable \"PREFIX\"\n",
    "os.environ[\"PREFIX\"] = \"INFER\"\n",
    "\n",
    "# Set the value of the environment variable \"HYDRA_FULL_ERROR\"\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "\n",
    "# Set the value of the environment variable \"USER\"\n",
    "os.environ[\"USER\"] = \"micro\"\n",
    "\n",
    "filename = \"/content/chunk2/eng_10_16k.wav\"\n",
    "\n",
    "# Open a file named \"output.txt\" in write mode\n",
    "with open('/content/chunk2/output.txt', 'w') as f:\n",
    "\n",
    "    # Command to run MMS inference\n",
    "    command = ['python', 'examples/mms/asr/infer/mms_infer.py', '--model', '/content/fairseq/models_new/mms1b_all.pt', '--lang', 'eng', '--audio', filename]\n",
    "\n",
    "    # Run the command and redirect the standard output to the file\n",
    "    subprocess.run(command, stdout=f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKWj0uyU7f7V"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "\n",
    "# URL of the video\n",
    "url = 'https://www.youtube.com/watch?v=T1WAHb47ChI&t=60s'\n",
    "\n",
    "youtube = YouTube(url)\n",
    "video = youtube.streams.filter(only_audio=True).first()\n",
    "out_file = video.download(output_path=\"/content/\")\n",
    "\n",
    "# Load the audio\n",
    "audio = AudioSegment.from_file(out_file, format=\"mp4\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('/content/chunk4', exist_ok=True)\n",
    "\n",
    "# Determine the end time for slicing in milliseconds\n",
    "end_time = 3*60*1000  # 3 minutes\n",
    "\n",
    "# Initialize start time and chunk size in milliseconds\n",
    "start_time = 0\n",
    "chunk_size = 60*1000  # 60 seconds\n",
    "\n",
    "# Slice and export each 60-second chunk of audio\n",
    "i = 0\n",
    "while start_time < end_time:\n",
    "    # Calculate the end time for the current slice\n",
    "    slice_end_time = min(start_time + chunk_size, end_time)\n",
    "    \n",
    "    # Slice the audio\n",
    "    sliced_audio = audio[start_time:slice_end_time]\n",
    "    \n",
    "    # Export the sliced audio\n",
    "    original_filename = f\"/content/chunk4/audio_{i}.wav\"\n",
    "    sliced_audio.export(original_filename, format=\"wav\")\n",
    "    \n",
    "    # Apply the ffmpeg process\n",
    "    output_filename = f\"/content/chunk4/urdu_{i}_16k.wav\"  # Updated filename\n",
    "    # convert to 16000 hz sample rate\n",
    "    command = ['ffmpeg', '-y', '-i', original_filename, '-ar', '16000', output_filename]\n",
    "    subprocess.run(command)\n",
    "    \n",
    "    # Move to the next slice\n",
    "    start_time += chunk_size\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_H1uh3MULP3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
    "os.environ[\"PYTHONPATH\"] = \".\"\n",
    "os.environ[\"PREFIX\"] = \"INFER\"\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "os.environ[\"USER\"] = \"micro\"\n",
    "\n",
    "# Define your directory\n",
    "directory = '/content/chunk4/'\n",
    "\n",
    "# Define the range of file indices\n",
    "file_indices = range(3)  # This will give you the numbers 0 to 2\n",
    "\n",
    "# Define a single output file to store all transcriptions\n",
    "combined_output_filename = os.path.join(directory, 'combined_transcription.txt')\n",
    "\n",
    "# Check if combined transcription file already exists and if so, remove it\n",
    "if os.path.exists(combined_output_filename):\n",
    "    os.remove(combined_output_filename)\n",
    "\n",
    "# Loop through the file indices\n",
    "for i in file_indices:\n",
    "    # Construct the input file name\n",
    "    input_filename = os.path.join(directory, f'eng_{i}_16k.wav')\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_filename):\n",
    "        print(f\"File {input_filename} does not exist, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Define the output filename for the transcription\n",
    "    output_filename = os.path.join(directory, f'transcription_{i}.txt')\n",
    "\n",
    "    # Open the transcription file in write mode\n",
    "    with open(output_filename, 'w') as f:\n",
    "        # Run the model inference on the audio file and save the output to the file\n",
    "        subprocess.run(['python', 'examples/mms/asr/infer/mms_infer.py', '--model', '/content/fairseq/models_new/mms1b_all.pt', '--lang', 'eng', '--audio', input_filename], stdout=f)\n",
    "\n",
    "    # Now, append the individual transcription to the combined file\n",
    "    with open(output_filename, 'r') as f_in, open(combined_output_filename, 'a') as f_out:\n",
    "        # Read the individual transcription and write it to the combined file\n",
    "        f_out.write(f_in.read())\n",
    "        # Optionally, write a newline character to separate the transcriptions\n",
    "        f_out.write('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_auto_caption",
   "language": "python",
   "name": "venv_auto_caption"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
